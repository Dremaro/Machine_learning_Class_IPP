{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es_iHEzxW190"
      },
      "source": [
        "# TP IMA205 - Coding Convolutional Neural Networks in Pytorch\n",
        "\n",
        "Practical work originally created by Alasdair Newson (https://sites.google.com/site/alasdairnewson/)\n",
        "\n",
        "For any remark or suggestion, please feel free to contact me at:\n",
        "\n",
        "- loic.lefolgoc@telecom-paris.fr\n",
        "\n",
        "### Objective:\n",
        "\n",
        "We want to implement a Convolutional Neural Network (CNN) for image recognition. For this we will use two well-known datasets, the first simpler and the second more complicated :\n",
        "\n",
        "- MNIST (images of digits)\n",
        "- CIFAR-10 dataset https://www.cs.toronto.edu/~kriz/cifar.html.\n",
        "\n",
        "The CIFAR-10 dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images.\n",
        "\n",
        "<br>We will first code the simple ConvNet described below using the Pytorch environment : https://pytorch.org/.\n",
        "\n",
        "- The input of the CNN is a set of (3,m,n) image tensors (m and n depend on the dataset).\n",
        "- We apply\n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same' (i.e. we apply zero-padding)\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same' (i.e. we apply zero-padding)\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    - a Max Pooling Layer of shape (2,2) and stride (2,2) (i.e. we reduce by two the size in each dimension)\n",
        "    - We then Flatten the data (reduce them to a vector in order to be able to apply a Fully-Connected layer to it)\n",
        "    - A softmax activation function which outputs are the $P(y_c | X)$ (multi-class problem)\n",
        "\n",
        "\n",
        "<IMG SRC='https://drive.google.com/uc?export=view&id=10xVi1LejX5TAI-tuOQM-UrSrNYa9gi0q'>\n",
        "    \n",
        "You should use the \"SAME\" border conditions.\n",
        "    \n",
        "### Your task:\n",
        "You need to add the missing parts in the code (parts between # --- START CODE HERE and # --- END CODE HERE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cgyu2GBVW192"
      },
      "source": [
        "# Load packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Qj5KY79W192"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHJ17JDiliHA"
      },
      "source": [
        "### CNN model in Pytorch\n",
        "\n",
        "There are several ways to write a CNN model in pytorch. In this lab, you will be using the _Sequential_ class of pytorch (similarly to Tensorflow). We will see the syntax further on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_S76Wi_W199"
      },
      "source": [
        "# Import data\n",
        "\n",
        "We first import the MNIST dataset. The training set is imported in `mnist_trainset` and the test set in `mnist_testset`.\n",
        "\n",
        "In practice, training on `mnist_trainset` takes too much time for this practical work. For this reason, we define a smaller training set (`mnist_trainset_reduced`) with a random subset of images. We will use `mnist_trainset_reduced` when training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BrYw9LK9W19-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7341bcd9-1de2-4af7-e316-617f79fa351c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 106533092.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 31236641.01it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 35319218.00it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 2573352.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Dataset MNIST\n",
            "    Number of datapoints: 60000\n",
            "    Root location: ./data\n",
            "    Split: Train\n",
            "    StandardTransform\n",
            "Transform: Compose(\n",
            "               ToTensor()\n",
            "           )\n"
          ]
        }
      ],
      "source": [
        "# Convert input to Pytorch tensors (ToTensor includes a rescaling from the range [0,255] to [0.0,1.0])\n",
        "input_transform=transforms.Compose([transforms.ToTensor()])\n",
        "\n",
        "# Download MNIST training data\n",
        "mnist_trainset = datasets.MNIST(root='./data',train=True,download=True,transform=input_transform)\n",
        "print(mnist_trainset)\n",
        "\n",
        "# Download test dataset\n",
        "mnist_testset = datasets.MNIST(root='./data',train=False,download=True,transform=input_transform)\n",
        "\n",
        "# Create data loader with smaller dataset size\n",
        "max_mnist_size = 2000\n",
        "mnist_trainset_reduced = torch.utils.data.random_split(mnist_trainset, [max_mnist_size, len(mnist_trainset)-max_mnist_size])[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also make a direct access to the training and test data as `torch` tensors. We will use them for visualization purposes and to compute the final training/test accuracies."
      ],
      "metadata": {
        "id": "NJ1vhc1SN_rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the actual data and labels\n",
        "X_train = torch.unsqueeze(mnist_trainset.data,axis=1)[mnist_trainset_reduced.indices]/255.0\n",
        "Y_train = mnist_trainset.targets[mnist_trainset_reduced.indices]\n",
        "X_test = torch.unsqueeze(mnist_testset.data,axis=1)/255.0\n",
        "Y_test = mnist_testset.targets"
      ],
      "metadata": {
        "id": "lXXsOChGKMO1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss6fBjWrAS4U"
      },
      "source": [
        "## Exploring the data\n",
        "\n",
        "We can explore the dataset `mnist_trainset` manually, although when we train the model, we will use the ```DataLoader``` of Pytorch (see later).\n",
        "\n",
        "The images are contained in a sub-structure of ```mnist_trainset``` called ```data```. The labels are contained in another sub-structure of ```mnist_trainset``` called ```targets```. Note that these are kept in their native format (the transformations are not applied to them), so to use them we have to apply the transformation manually, as above.\n",
        "\n",
        "__NOTE__ In general, if you want to find out what a structure contains, use the command ```dir()```, this will give you a list of the sub-structures.\n",
        "\n",
        "__NOTE__ `mnist_trainset_reduced` is a `Subset` object rather than a `Dataset` object. We cannot call `.data` and `.target` directly on it, although we can pass it as argument to a `DataLoader`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMqnFhbH9bcq"
      },
      "outputs": [],
      "source": [
        "print(dir(mnist_trainset))\n",
        "\n",
        "print(\"Size of training data : \", mnist_trainset.data.shape)\n",
        "print(\"Size of training labels : \", mnist_trainset.targets.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MnTkYmu-W1-E"
      },
      "source": [
        "The mnist dataset has 10 classes. These are the following :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvJ7McU7W1-F"
      },
      "outputs": [],
      "source": [
        "mnist_list = [ '0', '1','2','3','4','5','6','7','8','9']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6f_7d1NnW1-L"
      },
      "source": [
        "## Display some of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9OcnfCwbW1-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468
        },
        "outputId": "980b932c-66b7-40f1-81c4-485583de1595"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for idx in range(0,10):\n",
        "    plt.subplot(2, 5, idx+1)\n",
        "    rand_ind = np.random.randint(0,mnist_trainset.data.shape[0])\n",
        "    plt.imshow(mnist_trainset.data[rand_ind,:,:],cmap='gray')\n",
        "    plt.title(mnist_list[int(mnist_trainset.targets[rand_ind])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzRfY8QTBIX-"
      },
      "source": [
        "# Defining the model for MNIST\n",
        "\n",
        "We will now define the simple CNN described above, for use with MNIST. The input of the CNN is a set of (28,28,1) image tensors. We apply the following layers:\n",
        "\n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - a ReLu activation function\n",
        "    \n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - a ReLu activation function\n",
        "    - a Max Pooling Layer of shape (2,2) and stride (2,2) (i.e. we reduce by two the size in each dimension)\n",
        "    \n",
        "    - We then Flatten the data: reduce them to a vector in order to be able to apply a Fully-Connected layer to it\n",
        "    - Dense (fully connected) layer. Note, you will have to determine the input size, that is to say the number of elements after the last Max Pooling layer.\n",
        "\n",
        "__VERY IMPORTANT NOTE !!!__\n",
        "\n",
        "Pytorch carries out the softmax which we would expect at the end of our network automatically in the loss function that we will use, so there is no need to add it. Nevertheless, you must understand that the network output is a vector (of logits) which is _not_ normalised to be a probability distribution. This will be important later on.\n",
        "\n",
        "Now, we define the following hyper-parameters of the model :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T9d8TYFBONz"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "n_epochs = 10\n",
        "batch_size = 64\n",
        "nb_classes = int(mnist_trainset.targets.max()+1)\n",
        "\n",
        "nb_filters = 32       # number of convolutional filters to use\n",
        "kernel_size = (3, 3)  # convolution kernel size\n",
        "pool_size = (2, 2)    # size of pooling area for max pooling\n",
        "\n",
        "# --- Size of the successive layers\n",
        "n_h_0 = 1             # greyscale input images\n",
        "n_h_1 = nb_filters\n",
        "n_h_2 = nb_filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5MOihxZ-W1-W"
      },
      "source": [
        "# Model 1 : defining a CNN with the Sequential API of Pytorch for MNIST\n",
        "\n",
        "We are now going to create the CNN with Pytorch.\n",
        "\n",
        "The Sequential approach is quite similar to that of Tensorflow. To define a model, just write:\n",
        "\n",
        "```my_model = torch.nn.Sequential( first_layer, second_layer, ...)```\n",
        "\n",
        "Each layer must be a function imported from the Pytorch. You can use the following functions:\n",
        "\n",
        "- ```torch.nn.Conv2d()```\n",
        "- ```torch.nn.ReLU()```\n",
        "- ```torch.nn.MaxPool2d()```\n",
        "- ```torch.nn.Flatten()```\n",
        "- ```torch.nn.Linear()```\n",
        "\n",
        "Look at the documentation online to find the correct parameters. For example:\n",
        "\n",
        "- https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "npx-4C1SW1-X"
      },
      "outputs": [],
      "source": [
        "# BEGIN STUDENT CODE\n",
        "mnist_model = torch.nn.Sequential(xxx)\n",
        "# END STUDENT CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define dataloader"
      ],
      "metadata": {
        "id": "lWAn7YfDLtZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the ```torch.utils.data.DataLoader``` function of Pytorch to easily iterate over mini-batches of data. ```torch.utils.data.DataLoader``` is a useful function to extract batches of data from a dataset, applying the transformations which we have specified (conversion to Pytorch tensor, normalisation etc).\n",
        "\n",
        "We will train using the smaller training set, `mnist_trainset_reduced`."
      ],
      "metadata": {
        "id": "09fTmlMHLvNe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist_train_loader = torch.utils.data.DataLoader(mnist_trainset_reduced, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "mQ5bb_9kLvqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7FJS2SGeEwHF"
      },
      "source": [
        "## Define loss function and optimiser\n",
        "\n",
        "Pytorch provides an easy way to define the loss criterion to optimise. The syntax is (considering that the Adam optimiser is used):\n",
        "\n",
        "- ```criterion = torch.nn.BCELoss()``` or ```criterion = torch.nn.CrossEntropyLoss()```, etc., depending on your problem.\n",
        "- ```optimizer = torch.optim.Adam(mnist_model.parameters(), lr=learning_rate)```\n",
        "\n",
        "Fill in the following code, choosing the correct criterion to optimise. For the criterion, the individual loss over individual data samples can be aggregated into the total loss in several ways. Choose `reduction='sum'`, which takes the sum of individual losses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AK1pxqFCE090"
      },
      "outputs": [],
      "source": [
        "# BEGIN STUDENT CODE\n",
        "criterion = xxx\n",
        "optimizer = xxx\n",
        "# END STUDENT CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "42zy2XwsNfTQ"
      },
      "source": [
        "## CNN prediction conversion\n",
        "\n",
        "We recall here that the output of the classification CNN in Pytorch is a vector which is __NOT__ normalised to be a probability distribution. Therefore, for the purposes of finding the prediction of the CNN, we create a function which first converts an input vector to a probability distribution, and then determines the most likely class for each vector. The output should be, for each vector, an integer between 0 and (number of classes) $-1$.\n",
        "\n",
        "The inputs to this function will be Pytorch tensors, so you can use the following Pytorch functions on them :\n",
        "\n",
        "- ```torch.nn.Softmax()```\n",
        "- ```torch.argmax()```\n",
        "\n",
        "Create this function now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TqCPink-N1LB"
      },
      "outputs": [],
      "source": [
        "def vector_to_class(x):\n",
        "  # BEGIN STUDENT CODE\n",
        "  y = xxx\n",
        "  # END STUDENT CODE\n",
        "  return y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sYzRpoTgGhpG"
      },
      "source": [
        "## Accuracy\n",
        "\n",
        "Now, define a function which calculates the accuracy of the output of the neural network, with respect to the input labels. We consider that the input is a vector of class numbers (similar to the output of `vector_to_class`, but converted to a numpy array)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f4V5LKDhGsQT"
      },
      "outputs": [],
      "source": [
        "def cnn_accuracy(predict,labels):\n",
        "  # BEGIN STUDENT CODE\n",
        "  accuracy = xxx\n",
        "  # END STUDENT CODE\n",
        "  return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljHi0tfiW1-h"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now, we carry out the actual training of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HVe9ZWAdW1-h"
      },
      "outputs": [],
      "source": [
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "\n",
        "for epoch in range(0,n_epochs):\n",
        "  train_loss=0.0\n",
        "  all_labels = []\n",
        "  all_predicted = []\n",
        "\n",
        "  for batch_idx, (imgs, labels) in enumerate(mnist_train_loader):\n",
        "    # pass the samples through the network\n",
        "    predict = xxx # FILL IN STUDENT\n",
        "    # apply loss function\n",
        "    loss = xxx # FILL IN STUDENT\n",
        "    # set the gradients back to 0\n",
        "    xxx # FILL IN STUDENT\n",
        "    # backpropagation\n",
        "    xxx # FILL IN STUDENT\n",
        "    # parameter update\n",
        "    xxx # FILL IN STUDENT\n",
        "    # compute the train loss\n",
        "    train_loss += loss.item()\n",
        "    # store labels and class predictions\n",
        "    all_labels.extend(labels.tolist())\n",
        "    all_predicted.extend(vector_to_class(predict).tolist())\n",
        "\n",
        "  print('Epoch:{} Train Loss:{:.4f}'.format(epoch,train_loss/len(mnist_train_loader.dataset)))\n",
        "\n",
        "  # calculate accuracy\n",
        "  print('Accuracy:{:.4f}'.format(cnn_accuracy(np.array(all_predicted),np.array(all_labels))))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<br> Let's compute the final training and test accuracies:"
      ],
      "metadata": {
        "id": "m90MIu6PC96D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOsF40hkEqx1"
      },
      "outputs": [],
      "source": [
        "# Calculate accuracy on the training set and the test set\n",
        "\n",
        "# BEGIN FILL IN STUDENT (use X_train, Y_train, X_test, Y_test)\n",
        "predict_train = xxx\n",
        "predict_test = xxx\n",
        "\n",
        "train_accuracy = cnn_accuracy(xxx, xxx)\n",
        "test_accuracy = cnn_accuracy(xxx, xxx)\n",
        "# END FILL IN STUDENT\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRxCNvMO5Yzm"
      },
      "outputs": [],
      "source": [
        "print(\"Visual results : \")\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for idx in range(0,10):\n",
        "    plt.subplot(2, 5, idx+1)\n",
        "    rand_ind = np.random.randint(0,X_test.shape[0])\n",
        "    test_img = torch.unsqueeze(X_test[rand_ind,:,:,:],axis=1)\n",
        "    predicted_class = vector_to_class(mnist_model(test_img))\n",
        "    plt.imshow(test_img.squeeze(),cmap='gray')\n",
        "    plt.title(mnist_list[int(predicted_class)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5D5BY20W1-m"
      },
      "source": [
        "# Model 2: create a CNN on CIFAR10\n",
        "\n",
        "We are now going to train the same network architecture on a more difficult dataset : CIFAR-10\n",
        "\n",
        "First, we import the CIFAR-10 data and carry out some pre-processing :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k15abDeRW1-m"
      },
      "outputs": [],
      "source": [
        "# Convert input to Pytorch tensors\n",
        "input_transform=transforms.Compose( [transforms.ToTensor()])\n",
        "\n",
        "# Download CIFAR-10 training data\n",
        "cifar_trainset = datasets.CIFAR10(root='./data',train=True,download=True,transform=input_transform)\n",
        "print(cifar_trainset)\n",
        "\n",
        "# Download test dataset\n",
        "cifar_testset = datasets.CIFAR10(root='./data',train=False,download=True,transform=input_transform)\n",
        "\n",
        "# Create data loader with smaller dataset size\n",
        "max_cifar_size = 5000\n",
        "cifar_trainset_reduced = torch.utils.data.random_split(cifar_trainset, [max_cifar_size, len(cifar_trainset)-max_cifar_size])[0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the actual data and labels\n",
        "X_train = torch.from_numpy(cifar_trainset.data[cifar_trainset_reduced.indices]/255.0).float().permute(0,3,1,2)\n",
        "Y_train = torch.tensor(cifar_trainset.targets, dtype=torch.uint8)[cifar_trainset_reduced.indices]\n",
        "X_test = torch.from_numpy(cifar_testset.data/255.0).float().permute(0,3,1,2)\n",
        "Y_test = torch.tensor(cifar_testset.targets, dtype=torch.uint8)\n",
        "\n",
        "nb_channels = X_train.shape[1]"
      ],
      "metadata": {
        "id": "E1fWrMSmR16_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Al5b-S37T4A"
      },
      "outputs": [],
      "source": [
        "# The CIFAR10 categories\n",
        "cifar_10_list = [ 'airplane', 'automobile','bird','cat','deer','dog','frog','horse','ship','truck']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WpM3zdF_W1-x"
      },
      "source": [
        "## Display some of the images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PeFaoz2AW1-y"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "for idx in range(0,10):\n",
        "    plt.subplot(2, 5, idx+1)\n",
        "    rand_ind = np.random.randint(0,X_test.shape[0])\n",
        "    plt.imshow(X_test[rand_ind,:,:,:].permute(1,2,0))\n",
        "    plt.title(cifar_10_list[int(Y_test[rand_ind])])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XrGI_L3OW1-3"
      },
      "source": [
        "# Define the architecture again, for CIFAR-10\n",
        "\n",
        "In this case, we are going to add a layer because the data is more complex. Therefore, we use the following architecture :\n",
        "\n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    \n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    - a Max Pooling Layer of shape (2,2) and stride (2,2) (i.e. we reduce by two the size in each dimension)\n",
        "    \n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    - a Max Pooling Layer of shape (2,2) and stride (2,2) (i.e. we reduce by two the size in each dimension)\n",
        "\n",
        "    - a Convolutional layer of 32 filters of shape (3,3), with stride (1,1) and padding='same'\n",
        "    - additive biases\n",
        "    - a ReLu activation function\n",
        "    - a Max Pooling Layer of shape (2,2) and stride (2,2) (i.e. we reduce by two the size in each dimension)\n",
        "    \n",
        "    - We then Flatten the data (reduce them to a vector in order to be able to apply a Fully-Connected layer to it)\n",
        "    - Dense (fully connected) layer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OEs-EnXLW1-4"
      },
      "outputs": [],
      "source": [
        "learning_rate = 0.01\n",
        "n_epochs = 25\n",
        "batch_size = 256\n",
        "nb_classes = 10\n",
        "\n",
        "nb_filters = 32         # number of convolutional filters to use\n",
        "kernel_size = (3, 3)    # convolution kernel size\n",
        "pool_size = (2, 2)      # size of pooling area for max pooling\n",
        "\n",
        "# --- Size of the successive layers\n",
        "n_h_0 = nb_channels\n",
        "n_h_1 = nb_filters\n",
        "n_h_2 = nb_filters\n",
        "n_h_3 = nb_filters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I0ACZkTFW1-7"
      },
      "source": [
        "Now, modify the previous code (you can copy/paste/modify the necessary parts) to define the model for CIFAR-10."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RmbX6oq0W1-7"
      },
      "outputs": [],
      "source": [
        "# BEGIN STUDENT CODE\n",
        "cifar_model = torch.nn.Sequential(xxx)\n",
        "\n",
        "cifar_train_loader = xxx\n",
        "criterion = xxx\n",
        "optimizer = xxx\n",
        "# END STUDENT CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KUmQKIEe8_QU"
      },
      "source": [
        "Now, carry out training on the CIFAR-10 dataset (use the previous code as an example)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pyEwLnLR9gv0"
      },
      "outputs": [],
      "source": [
        "# BEGIN STUDENT CODE\n",
        "\n",
        "# END STUDENT CODE"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Print the training and test accuracy (use the previous code as an example):"
      ],
      "metadata": {
        "id": "18xwDDSTKPap"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate accuracy on the training set and the test set\n",
        "\n",
        "# BEGIN FILL IN STUDENT (use X_train, Y_train, X_test, Y_test)\n",
        "\n",
        "# END STUDENT CODE\n",
        "\n",
        "print(\"Train Accuracy:\", train_accuracy)\n",
        "print(\"Test Accuracy:\", test_accuracy)"
      ],
      "metadata": {
        "id": "a8VvPS8WQ92b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "afxhSlTZW1_A"
      },
      "source": [
        " What do you think about the results (better or worse than MNIST) ? Why do you think this is ? How could you improve the results ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sIvS5eHEW1_A"
      },
      "source": [
        "# Visualising the convolutional weights\n",
        "\n",
        "You can explore the network parameters easily with Pytroch. Indeed, your model ```cifar_model``` is simply a list of layers, thus you can access the first layer with :\n",
        "- ```cifar_model[0]```\n",
        "\n",
        "If you want to find out the contents of this layer, use :\n",
        "\n",
        "```dir(cifar_model[0])```\n",
        "\n",
        "In particular, the convolutional weights are contained in the ```weights``` sub-structure (a multi-dimensional array). Note that this weight's size is :\n",
        "\n",
        "- $[n_{filters}, n_{channels}, y_{size}, x_{size}]$\n",
        "\n",
        "Now, display all (32) trained filters of the first convolutional layer, taking only the first channel of each filter :"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BahI3aUN-3fG"
      },
      "outputs": [],
      "source": [
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "for num in range(0,32):\n",
        "    plt.subplot(8, 4, num+1)\n",
        "    # --- START CODE HERE\n",
        "    plt.imshow((xxx).detach().numpy(),cmap='gray')\n",
        "    # --- END CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zX6yNSiKBXDH"
      },
      "source": [
        "What do you think ? Pretty incomprehensible no ? Do not spend too long trying to interpret these filters, that way madness lies.\n",
        "\n",
        "So, it seems that understanding a CNN by just looking at the filters is an exercise in futility. How can we do better ? Well, take a look at part 2 of the lab !"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation\n",
        "\n",
        "To evaluate the work, you should rate the code for\n",
        "- 1) MNIST : Defining the first model : 3 points\n",
        "- 2) MNIST : Compiling and training the first model : 1 point\n",
        "- 3) CIFAR10 : Defining the second model : 3 points\n",
        "- 4) CIFAR10 : Compiling and training the second model : 1 point\n",
        "- 5) Calculating ```predicted_class``` : 1 point\n",
        "- 6) Correctly visualising the weights : 1 point\n",
        "\n",
        "\n",
        "Total over 10 points. For the questions with three points :\n",
        "- 1 point if partially correct\n",
        "- 2 points if correct code but does not give the expected results. Be careful, sometimes the training might get stuck quickly by bad luck : restart the code a few times to make sure it is indeed a bug.\n",
        "- 3 points for correct code and correct execution"
      ],
      "metadata": {
        "id": "LydLzTUNLGYJ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2I_qtxjpxiyZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}